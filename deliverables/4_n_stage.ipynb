{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #bfd630; font-family: Calibri, sans-serif; padding: 20px;\">\n",
    "\n",
    "\n",
    "\n",
    "   <div style=\"text-align: center;\">\n",
    "      <img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTaJWG7PzF3toxaRMB1-JicpqMgJuEXATd0fg&\" style=\"width: 120px; margin-top: 20px; margin-bottom: 60px;\">\n",
    "   </div>\n",
    "\n",
    "   <div style=\"text-align: center; font-size: 24px; font-weight: bold; font-family: Calibri; color: #000000; margin-bottom: 10px;\">\n",
    "      Machine Learning Project | To Grant or Not to Grant\n",
    "   </div>\n",
    "   <div style=\"text-align: center; font-family: Calibri; font-size: 22px; color: #000000; font-weight: bold; margin-bottom: 20px;\">\n",
    "      4. N-Stage-Model\n",
    "   </div>\n",
    "\n",
    "   <div style=\"text-align: center; font-size: 18px; font-family: Calibri; font-weight: bold; color: #333333; margin-bottom: 5px;\">\n",
    "      Nova Information Management School\n",
    "   </div>\n",
    "\n",
    "   <div style=\"text-align: center; font-size: 18px; font-family: Calibri; font-weight: bold; color: #333333; margin-bottom: 20px;\">\n",
    "      Universidade Nova de Lisboa\n",
    "   </div>\n",
    "        <div style=\"text-align: center; font-size: 16px; font-family: Calibri; font-weight: bold; color: #333333; margin-bottom: 10px;\">\n",
    "      Master in Data Science and Advanced Analytics\n",
    "   </div>\n",
    " \n",
    "   <div style=\"text-align: center;\">\n",
    "      <img src=\"https://cdn.prod.website-files.com/617accb8b04ef2b3feffa61b/6581e90d485a9976c3576a46_how-does-workers-comp-work.jpg\" style=\"width: 350px; margin-top: 20px; margin-bottom: 60px;\">\n",
    "   </div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   <div style=\"text-align: center; font-family: Calibri; font-size: 16px; color: #333333; font-weight: bold; margin-bottom: 20px;\">\n",
    "      Project Group: 32\n",
    "   </div>\n",
    "\n",
    "   <div style=\"text-align: center; font-family: Calibri; font-size: 16px; color: #333333; margin-bottom: 40px\">\n",
    "      Klimentina Gilevska -  20240747 <br>\n",
    "      Maria Assunção -  20211605 <br>\n",
    "      Rita Matos -  20211642 <br>\n",
    "      Rita Wang -  20240551 <br>\n",
    "      Sven Goerdes -  20240503\n",
    "   </div>\n",
    "\n",
    "   <div style=\"text-align: center; font-family: Calibri; font-size: 16px; color: #333333; margin-bottom: 10px\">\n",
    "      Fall/Spring Semester 2024-2025\n",
    "   </div>\n",
    "\n",
    "  <div style=\"text-align: center; font-family: Calibri; font-size: 16px; color: #333333; margin-bottom: 20px;\">\n",
    "      22nd of December 2024\n",
    "   </div>\n",
    "\n",
    "   \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import pandas as pd  # For creating and handling DataFrames\n",
    "import numpy as np  # For numerical operations\n",
    "import matplotlib.pyplot as plt  # For visualizations\n",
    "import seaborn as sns  # For statistical data visualization\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Correlation Heatmap\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Statistical Tests\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency  # For Cramér's V calculation\n",
    "from sklearn.feature_selection import chi2  # For Chi-square test\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Cross-Validation and Grid Search\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Resampling Techniques\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# import functions in helper functions folder \n",
    "import sys\n",
    "sys.path.append('../helper_functions')\n",
    "# Import functions that are stored in the helper_functions directory. We do this to keep the notebook clean and easy to read\n",
    "from helper_functions import *\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "X_train_encoded = pd.read_csv('../project_data/X_train_encoded.csv', delimiter=',', index_col=0)\n",
    "X_val_encoded = pd.read_csv('../project_data/X_val_encoded.csv', delimiter=',', index_col=0)\n",
    "\n",
    "y_train = pd.read_csv('../project_data/y_train.csv',delimiter=',', index_col=0)\n",
    "y_val= pd.read_csv('../project_data/y_val.csv', delimiter=',', index_col=0)\n",
    "\n",
    "X_test_encoded = pd.read_csv('../project_data/X_test_encoded.csv',index_col=0)\n",
    "\n",
    "# The datasets are split into training, validation, and testing sets to ensure proper evaluation and independence during modeling.\n",
    "\n",
    "# The training and validation datasets are loaded to facilitate supervised learning tasks. Splitting the data ensures unbiased evaluation of models during validation and testing. The test dataset remains untouched until the final evaluation phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification dataset\n",
    "X_train_encoded_bin = pd.read_csv('../project_data/X_train_encoded_binary.csv', delimiter=',', index_col=0)\n",
    "X_val_encoded_bin = pd.read_csv('../project_data/X_val_encoded_binary.csv', delimiter=',', index_col=0)\n",
    "\n",
    "y_train_bin = pd.read_csv('../project_data/y_train_binary.csv',delimiter=',', index_col=0)\n",
    "y_val_bin= pd.read_csv('../project_data/y_val_binary.csv', delimiter=',', index_col=0)\n",
    "\n",
    "X_test_encoded_bin = pd.read_csv('../project_data/X_test_encoded_binary.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Encoding multiclass target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Encode the multiclass target and exclude 2. NON-COMP from the dataset, so it's easier to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_injury_type_mapping = {\n",
    "    '4. TEMPORARY': 0,\n",
    "    '2. NON-COMP':7,\n",
    "    '5. PPD SCH LOSS': 1,\n",
    "    '3. MED ONLY': 2,\n",
    "    '6. PPD NSL': 3,\n",
    "    '1. CANCELLED': 4,\n",
    "    '8. DEATH':5,\n",
    "    '7. PTD': 6\n",
    "}\n",
    "\n",
    "y_train_encoded = y_train['Claim Injury Type'].map(claim_injury_type_mapping)\n",
    "y_val_encoded = y_val['Claim Injury Type'].map(claim_injury_type_mapping)\n",
    "y_val_encoded_final = y_val['Claim Injury Type'].map(claim_injury_type_mapping)\n",
    "X_val_encoded_final = X_val_encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure y_train is a Series (if it's a DataFrame with one column, convert it to Series)\n",
    "y_train = y_train.squeeze()  # This will convert DataFrame with a single column to a Series\n",
    "\n",
    "# Create a mask for rows where '2. NON-COMP' is not present\n",
    "mask = y_train != '2. NON-COMP'\n",
    "\n",
    "# Apply the mask to filter out '2. NON-COMP'\n",
    "y_train_not_encoded = y_train[mask]\n",
    "\n",
    "# Print the shape of the filtered target\n",
    "print(\"Shape of y_train_not_encoded:\", y_train_not_encoded.shape)\n",
    "\n",
    "# Check the unique classes in the filtered target to confirm that '2. NON-COMP' is removed\n",
    "print(\"Classes in y_train_not_encoded:\", y_train_not_encoded.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where y_train_encoded is not equal to 7 (non-comp class)\n",
    "mask_train = y_train_encoded != 7\n",
    "\n",
    "# Filter X_train_encoded and y_train_encoded based on the mask\n",
    "X_train_encoded = X_train_encoded[mask_train]\n",
    "y_train_encoded = y_train_encoded[mask_train]\n",
    "\n",
    "# Apply the same mask to y_val_encoded and X_val_encoded\n",
    "mask_val = y_val_encoded != 7\n",
    "X_val_encoded = X_val_encoded[mask_val]\n",
    "y_val_encoded = y_val_encoded[mask_val]\n",
    "\n",
    "# Verify the shapes of the new filtered datasets\n",
    "print(\"Shape of X_train_encoded_filtered:\", X_train_encoded.shape)\n",
    "print(\"Shape of y_train_encoded_filtered:\", y_train_encoded.shape)\n",
    "print(\"Shape of X_val_encoded_filtered:\", X_val_encoded.shape)\n",
    "print(\"Shape of y_val_encoded_filtered:\", y_val_encoded.shape)\n",
    "\n",
    "# Check unique classes in the target to confirm \"non comp\" is removed\n",
    "print(\"Classes in y_train_encoded_filtered:\", y_train_encoded.unique())\n",
    "print(\"Classes in y_val_encoded_filtered:\", y_val_encoded.unique())  # Corrected this line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Separate Numerical and Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1  Binary separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Separare the Numerical and Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns_bin = ['Age at Injury', \n",
    "                   'IME-4 Count', \n",
    "                   'Number of Dependents',\n",
    "\n",
    "                   'Industry Code_encoded_0',\n",
    "                   'Industry Code_encoded_1', \n",
    "\n",
    "                   'WCIO Cause of Injury Code_encoded_0',\n",
    "                   'WCIO Cause of Injury Code_encoded_1',\n",
    "\n",
    "                   'WCIO Nature of Injury Code_encoded_0',\n",
    "                   'WCIO Nature of Injury Code_encoded_1',\n",
    "\n",
    "                   'WCIO Part Of Body Code_encoded_0', \n",
    "                   'WCIO Part Of Body Code_encoded_1',\n",
    "\n",
    "                   'Industry Code_freq', \n",
    "                   'WCIO Cause of Injury Code_freq',\n",
    "                   'WCIO Nature of Injury Code_freq',\n",
    "                   'WCIO Part Of Body Code_freq',\n",
    "                   'Carrier Type_freq', \n",
    "                   'Carrier Name_freq',\n",
    "                   'Accident Datemonth',\n",
    "                   'Accident Date_Season_Spring', \n",
    "                   'Accident Date_Season_Summer',\n",
    "                   'Accident Date_Season_Winter',\n",
    "                   'Days_between_C-2 Date_Accident Date_log',\n",
    "\n",
    "                   'Days_between_Assembly Date_Accident Date_log',\n",
    "                   'Average Weekly Wage Imputed_log']\n",
    "\n",
    "cat_columns_bin = ['Carrier Type_Self-insured Private Entity',\n",
    "                   'Carrier Type_Self-insured Public Entity', \n",
    "                   'Carrier Type_Special Funds',\n",
    "                   'Carrier Type_State Insurance Fund', \n",
    "                   'C-3 Date_nabinary', \n",
    "                   'Average Weekly Wage_nabinary',\n",
    "                   'First Hearing Date_nabinary',\n",
    "                   'Alternative Dispute Resolution_binary',\n",
    "                   'COVID-19 Indicator_binary',\n",
    "                   'Attorney/Representative_binary']\n",
    "\n",
    "# Create subsets\n",
    "X_train_num_bin = X_train_encoded_bin[num_columns_bin]\n",
    "X_train_cat_bin = X_train_encoded_bin[cat_columns_bin]\n",
    "\n",
    "X_val_num_bin = X_val_encoded_bin[num_columns_bin]\n",
    "X_val_cat_bin = X_val_encoded_bin[cat_columns_bin]\n",
    "\n",
    "X_test_num_bin=X_test_encoded_bin[num_columns_bin]\n",
    "X_test_cat_bin=X_test_encoded_bin[cat_columns_bin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Multiclass separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Drop the ones associated the the target class 2. NON-COMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features associated with \"non comp\" in their name\n",
    "columns_to_drop = [col for col in X_train_encoded.columns if \"non-comp\" in col.lower()]\n",
    "\n",
    "# Drop the columns from the dataset\n",
    "X_train_encoded = X_train_encoded.drop(columns=columns_to_drop)\n",
    "X_val_encoded = X_val_encoded.drop(columns=columns_to_drop)  # If you have validation data\n",
    "X_test_encoded = X_test_encoded.drop(columns=columns_to_drop)  # If you have test data\n",
    "\n",
    "# Verify the remaining columns\n",
    "print(\"Remaining columns after dropping 'non comp' features:\")\n",
    "print(len(X_train_encoded.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Separate the numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = ['Age at Injury', \n",
    "               'IME-4 Count', \n",
    "               'Number of Dependents',\n",
    "               \n",
    "               'Industry Code_encoded_5. PPD SCH LOSS',\n",
    "               'Industry Code_encoded_3. MED ONLY',\n",
    "               'Industry Code_encoded_4. TEMPORARY',\n",
    "               'Industry Code_encoded_1. CANCELLED', \n",
    "               'Industry Code_encoded_8. DEATH',\n",
    "               'Industry Code_encoded_6. PPD NSL', \n",
    "               'Industry Code_encoded_7. PTD',\n",
    "               \n",
    "               'WCIO Cause of Injury Code_encoded_5. PPD SCH LOSS',\n",
    "               'WCIO Cause of Injury Code_encoded_3. MED ONLY',\n",
    "               'WCIO Cause of Injury Code_encoded_4. TEMPORARY',\n",
    "               'WCIO Cause of Injury Code_encoded_1. CANCELLED',\n",
    "               'WCIO Cause of Injury Code_encoded_8. DEATH',\n",
    "               'WCIO Cause of Injury Code_encoded_6. PPD NSL',\n",
    "               'WCIO Cause of Injury Code_encoded_7. PTD',\n",
    "               \n",
    "               'WCIO Nature of Injury Code_encoded_5. PPD SCH LOSS',\n",
    "               'WCIO Nature of Injury Code_encoded_3. MED ONLY',\n",
    "               'WCIO Nature of Injury Code_encoded_4. TEMPORARY',\n",
    "               'WCIO Nature of Injury Code_encoded_1. CANCELLED',\n",
    "               'WCIO Nature of Injury Code_encoded_8. DEATH',\n",
    "               'WCIO Nature of Injury Code_encoded_6. PPD NSL',\n",
    "               'WCIO Nature of Injury Code_encoded_7. PTD',\n",
    "               \n",
    "               'WCIO Part Of Body Code_encoded_5. PPD SCH LOSS',\n",
    "               'WCIO Part Of Body Code_encoded_3. MED ONLY',\n",
    "               'WCIO Part Of Body Code_encoded_4. TEMPORARY',\n",
    "               'WCIO Part Of Body Code_encoded_1. CANCELLED',\n",
    "               'WCIO Part Of Body Code_encoded_8. DEATH',\n",
    "               'WCIO Part Of Body Code_encoded_6. PPD NSL',\n",
    "               'WCIO Part Of Body Code_encoded_7. PTD',\n",
    "               \n",
    "               'Industry Code_freq',\n",
    "               'WCIO Cause of Injury Code_freq', \n",
    "               'WCIO Nature of Injury Code_freq',\n",
    "               'WCIO Part Of Body Code_freq', \n",
    "               'Carrier Type_freq',\n",
    "               'Carrier Name_freq',\n",
    "               \n",
    "               'Accident Datemonth',\n",
    "               'Accident Date_Season_Spring', \n",
    "               'Accident Date_Season_Summer',\n",
    "               'Accident Date_Season_Winter',\n",
    "\n",
    "               'Days_between_Assembly Date_Accident Date_log',\n",
    "               'Days_between_C-2 Date_Accident Date_log',\n",
    "               'Average Weekly Wage Imputed_log']\n",
    "\n",
    "cat_columns =['Carrier Type_Self-insured Private Entity',\n",
    "               'Carrier Type_Self-insured Public Entity', \n",
    "               'Carrier Type_Special Funds',\n",
    "               'Carrier Type_State Insurance Fund', \n",
    "               'C-3 Date_nabinary', \n",
    "               'Average Weekly Wage_nabinary',\n",
    "               'First Hearing Date_nabinary',\n",
    "               'Alternative Dispute Resolution_binary',\n",
    "               'COVID-19 Indicator_binary',\n",
    "               'Attorney/Representative_binary']\n",
    "\n",
    "\n",
    "# Create subsets\n",
    "X_train_num = X_train_encoded[num_columns]\n",
    "X_train_cat = X_train_encoded[cat_columns]\n",
    "\n",
    "X_val_num = X_val_encoded[num_columns]\n",
    "X_val_cat = X_val_encoded[cat_columns]\n",
    "\n",
    "X_test_num=X_test_encoded[num_columns]\n",
    "X_test_cat=X_test_encoded[cat_columns]\n",
    "\n",
    "X_val_final_num = X_val_encoded_final[num_columns]\n",
    "X_val_final_cat = X_val_encoded_final[cat_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Scale non-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We decided to use normalization because it does not assume any specific distribution of the data. Instead, it scales all features to fit within a specified range—in our case, [0, 1]. This approach can be particularly effective for data that does not follow a Gaussian distribution or has outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(X_train_num)\n",
    "X_train_num_scaled = scaler.transform(X_train_num)\n",
    "# print(\"Parameters fitted:\")\n",
    "# for feature, min_val, max_val in zip(X_train_num.columns, scaler.data_min_, scaler.data_max_):\n",
    "    # print(f\"Variable: {feature} | Min: {min_val} | Max: {max_val}\")\n",
    "\n",
    "# Convert the array to a pandas dataframe\n",
    "X_train_num_scaled = pd.DataFrame(X_train_num_scaled, columns = X_train_num.columns).set_index(X_train_encoded.index)\n",
    "# X_train_num_scaled.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_num_scaled = scaler.transform(X_val_num)\n",
    "X_val_num_scaled = pd.DataFrame(X_val_num_scaled, columns = X_val_num.columns).set_index(X_val_encoded.index)\n",
    "# X_val_num_scaled.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_num_scaled = scaler.transform(X_test_num)\n",
    "X_test_num_scaled = pd.DataFrame(X_test_num_scaled, columns = X_test_num.columns).set_index(X_test_encoded.index)\n",
    "# X_test_num_scaled.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Scale binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Peform the same for binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(X_train_num_bin)\n",
    "X_train_num_scaled_bin = scaler.transform(X_train_num_bin)\n",
    "# print(\"Parameters fitted:\")\n",
    "# for feature, min_val, max_val in zip(X_train_num.columns, scaler.data_min_, scaler.data_max_):\n",
    "    # print(f\"Variable: {feature} | Min: {min_val} | Max: {max_val}\")\n",
    "\n",
    "# Convert the array to a pandas dataframe\n",
    "X_train_num_scaled_bin = pd.DataFrame(X_train_num_scaled_bin, columns = X_train_num_bin.columns).set_index(X_train_encoded_bin.index)\n",
    "# X_train_num_scaled.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_num_scaled_bin = scaler.transform(X_val_num_bin)\n",
    "X_val_num_scaled_bin = pd.DataFrame(X_val_num_scaled_bin, columns = X_val_num_bin.columns).set_index(X_val_encoded_bin.index)\n",
    "# X_val_num_scaled.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_num_scaled_bin = scaler.transform(X_test_num_bin)\n",
    "X_test_num_scaled_bin = pd.DataFrame(X_test_num_scaled_bin, columns = X_test_num_bin.columns).set_index(X_test_encoded_bin.index)\n",
    "# X_test_num_scaled.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binary: Feature selection\n",
    ">- Identify relevant features for binary classification tasks by evaluating their relationship with the target variable\n",
    ">- Mutual Information and Chi-square tests are applied to measure feature importance and select significant features\n",
    ">- Simplify the dataset while retaining the most predictive features for the binary model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Filter Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeeze the y_train_bin\n",
    "y_train_bin = y_train_bin.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Applied without the target being encoded as it avoids introducing false ordinal relationships. Since all 3 (Chi-square, Cramer's V, Chi-Square) can handle categorical data directly, it’s better to not encode it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Chi-square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> These features have **p-value < 0.05** and a **Cramér's V ≥ 0.1**, which indicates:\n",
    "\n",
    "> - **Strong Statistical Association**: The feature is significantly associated with the target variable.\n",
    "> - **Practical Importance**: Cramér's V suggests a meaningful strength of association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Chi-square test\n",
    "chi2_values, p_values = chi2(X_train_cat_bin, y_train_bin)\n",
    "\n",
    "# Create DataFrame for Chi-square results\n",
    "chi2_results = pd.DataFrame({\n",
    "    'Column': X_train_cat_bin.columns,\n",
    "    'Chi2': chi2_values.round(5),\n",
    "    'p-value': p_values.round(5)\n",
    "})\n",
    "\n",
    "# Calculate Cramér's V for binary target\n",
    "cramers_v_values = []\n",
    "for var in X_train_cat_bin.columns:\n",
    "    v = cramers_v(X_train_cat_bin[var], y_train_bin)\n",
    "    cramers_v_values.append(v)\n",
    "\n",
    "# Add Cramér's V to DataFrame\n",
    "chi2_results['Cramér\\'s V'] = cramers_v_values\n",
    "\n",
    "# Filter important features\n",
    "chi2_important_features = chi2_results[(chi2_results['p-value'] < 0.05) & (chi2_results['Cramér\\'s V'] >= 0.1)]\n",
    "\n",
    "list_features_chi2_cramer = chi2_important_features['Column'].values\n",
    "\n",
    "print(chi2_important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Given that Mutual Information can measure the dependence between categorical variables and the target. We have decided to keep any features that have mutual informatio > 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mutual information for categorical features\n",
    "mi_scores = mutual_info_classif(X_train_cat_bin, y_train_bin, discrete_features=True)\n",
    "\n",
    "# Create DataFrame of results\n",
    "mi_cat_results = pd.DataFrame({\n",
    "    'Feature': X_train_cat_bin.columns,\n",
    "    'Mutual Information': mi_scores\n",
    "}).sort_values(by='Mutual Information', ascending=False)\n",
    "\n",
    "mi_cat_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_important_features = mi_cat_results[mi_cat_results['Mutual Information'] > 0.01]\n",
    "\n",
    "list_features_mi = mi_cat_results[mi_cat_results['Mutual Information'] > 0.01]['Feature'].values\n",
    "\n",
    "print(mi_important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 Filtered Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Keep if selected by either Chi-square and Cramer's V or Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features that appear in at least one of the important feature sets\n",
    "selected_features = list(set(list_features_chi2_cramer) | set(list_features_mi)) \n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features =['Carrier Type_State Insurance Fund',\n",
    " 'Average Weekly Wage_nabinary',\n",
    " 'Attorney/Representative_binary',\n",
    " 'C-3 Date_nabinary',\n",
    " 'First Hearing Date_nabinary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only selected important features in the datasets\n",
    "X_train_cat_filtered_bin = X_train_cat_bin[selected_features]\n",
    "X_val_cat_filtered_bin = X_val_cat_bin[selected_features]\n",
    "X_test_cat_filtered_bin = X_test_cat_bin[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Filter Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Univariate variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num_scaled_bin.var().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No need to remove any, as there are no features with zero variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Spearman Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Spearman correlation matrix for numerical features\n",
    "cor_spearman = X_train_num_scaled_bin.corr(method='spearman')\n",
    "\n",
    "# Flatten the correlation matrix and reset the index\n",
    "correlation_pairs = cor_spearman.unstack().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "correlation_pairs.columns = ['Feature_1', 'Feature_2', 'Correlation']\n",
    "\n",
    "# Filter the table for correlations > 0.8 or < -0.8 and exclude self-correlations (diagonal)\n",
    "strong_correlations = correlation_pairs[\n",
    "    ((correlation_pairs['Correlation'] > 0.8) | (correlation_pairs['Correlation'] < -0.8)) & \n",
    "    (correlation_pairs['Feature_1'] != correlation_pairs['Feature_2'])\n",
    "]\n",
    "\n",
    "# Remove duplicate pairs by keeping only one order\n",
    "strong_correlations = strong_correlations[\n",
    "    strong_correlations['Feature_1'] < strong_correlations['Feature_2']\n",
    "]\n",
    "\n",
    "# Sort by correlation value\n",
    "strong_correlations = strong_correlations.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "# Display the table\n",
    "strong_correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features with strong correlation (correlation > 0.8 or < -0.8)\n",
    "strong_correlation_features = list(pd.concat([strong_correlations['Feature_2']]).unique())\n",
    "\n",
    "# Display the list of features with strong correlations\n",
    "print(strong_correlation_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <code>WCIO Part Of Body Code_encoded_0</code> and <code>WCIO Part Of Body Code_encoded_1</code> and the other target encoded variables have -1 correlation, which is to be expected because it was binary encoded. We'll remove one of them. As well as remove <code>Days_between_C-2 Date_Accident Date_log</code> as we believe that <code>\tDays_between_Assembly Date_Accident Date_log</code> might be more meaningful since it had no missing values to begin with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mutual information between categorical features and target\n",
    "mutual_info = mutual_info_classif(X_train_num_scaled_bin, y_train_bin)\n",
    "\n",
    "# Display features sorted by mutual information\n",
    "mi_results = pd.DataFrame({\n",
    "    'Feature': X_train_num_scaled_bin.columns,\n",
    "    'Mutual Information': mutual_info\n",
    "}).sort_values(by='Mutual Information', ascending=False)\n",
    "\n",
    "mi_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `mutual_info` is the result from `mutual_info_classif` function\n",
    "mi_results = pd.DataFrame({\n",
    "    'Feature': X_train_num_scaled_bin.columns,\n",
    "    'Mutual Information': mutual_info\n",
    "}).sort_values(by='Mutual Information', ascending=False)\n",
    "\n",
    "# Filter features with Mutual Information > 0.01\n",
    "mi_important_features = mi_results[mi_results['Mutual Information'] > 0.01]\n",
    "\n",
    "# Display the important features\n",
    "print(mi_important_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Threshold of 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features with Mutual Information > 0.01\n",
    "mi_non_important = mi_results[mi_results['Mutual Information'] < 0.01]['Feature'].tolist()\n",
    "mi_non_important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Filtered Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Drop features that have high correlation and mutual information < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_to_drop =list(set(num_features_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features to drop from X_train_num_scaled\n",
    "num_features_to_drop = list(set(strong_correlation_features + mi_non_important))\n",
    "\n",
    "# Drop features\n",
    "X_train_num_scaled_filtered_bin = X_train_num_scaled_bin.drop(columns=num_features_to_drop)\n",
    "X_val_num_scaled_filtered_bin = X_val_num_scaled_bin.drop(columns=num_features_to_drop)\n",
    "X_test_num_scaled_filtered_bin = X_test_num_scaled_bin.drop(columns=num_features_to_drop)\n",
    "\n",
    "# Verify the remaining columns\n",
    "print(\"Remaining features in X_train_num_scaled:\", X_train_num_scaled_filtered_bin.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Combine the Filtered Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Combine the datasets after dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the filtered datasets\n",
    "X_train_bin = pd.concat([X_train_cat_filtered_bin, X_train_num_scaled_filtered_bin], axis=1)\n",
    "X_val_bin =  pd.concat([X_val_cat_filtered_bin, X_val_num_scaled_filtered_bin], axis=1)\n",
    "X_test_bin =  pd.concat([X_test_cat_filtered_bin, X_test_num_scaled_filtered_bin], axis=1)\n",
    "\n",
    "\n",
    "# Verify the shape of the combined dataset\n",
    "print(\"Shape of combined X_train:\", X_train_bin.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use this for the binary, as we will be dropping later for multiclass in minority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Feature Selection with All Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1 RFE WITH Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Feature select with RFE and Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = pd.Series(y_train_bin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Given that here our target is binary and is balanced, we can just use accuracy instead of f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "log_reg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Sample 1% of the data\n",
    "sample_size = int(0.5 * len(X_train_bin))  # 50% of the dataset\n",
    "X_train_sample = X_train_bin.sample(n=sample_size, random_state=42)\n",
    "y_train_sample = y_train_bin.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Loop over different numbers of features\n",
    "feature_counts = range(1, X_train_sample.shape[1] + 1)\n",
    "scores = []\n",
    "\n",
    "# Loop through each feature count and evaluate the model's performance\n",
    "for n in feature_counts:\n",
    "    rfe = RFE(log_reg_model, n_features_to_select=n)\n",
    "    rfe.fit(X_train_sample, y_train_sample)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = X_train_sample.columns[rfe.support_]\n",
    "    \n",
    "    # Evaluate performance using cross-validation with F1 score as the metric\n",
    "    score = cross_val_score(log_reg_model, X_train_sample[selected_features], y_train_sample, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "# Find the number of features that gives the highest F1 score\n",
    "best_n_features = feature_counts[np.argmax(scores)]\n",
    "print(f\"Optimal number of features: {best_n_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train_bin and y_train_bin are your features and target\n",
    "\n",
    "# Step 1: Take a smaller sample (e.g., 50% of the data)\n",
    "sample_size = int(0.5 * len(X_train_bin))  # 10% of the dataset\n",
    "X_train_sample = X_train_bin.sample(n=sample_size, random_state=42)\n",
    "y_train_sample = y_train_bin.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Step 2: Initialize Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Step 3: Apply RFE to the sample data\n",
    "rfe = RFE(logistic_model, n_features_to_select=6)\n",
    "rfe.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Step 4: Get the selected features\n",
    "selected_features_rfe = X_train_sample.columns[rfe.support_]\n",
    "\n",
    "# Print selected features\n",
    "print(\"Selected Features after RFE with Logistic Regression:\")\n",
    "print(selected_features_rfe)\n",
    "\n",
    "# Optionally, you can use the selected features to transform the dataset\n",
    "X_train_selected_rfe = X_train_sample[selected_features_rfe]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2 Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = LassoCV(cv=5)  # Cross-validation to select optimal alpha\n",
    "lasso.fit(X_train_bin, y_train_bin)\n",
    "lasso_features = X_train_bin.columns[lasso.coef_ != 0]\n",
    "print(\"Selected features by Lasso:\", lasso_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.3 Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Find best threshold for ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model\n",
    "ridge = Ridge()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(ridge, param_grid, cv=5)\n",
    "grid_search.fit(X_train_bin, y_train_bin)\n",
    "\n",
    "# Get the best alpha\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "print(f\"Best alpha value: {best_alpha}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ridge regression model with cross-validation\n",
    "ridge_model = RidgeCV(cv=5)\n",
    "\n",
    "# Fit the model on the training data\n",
    "ridge_model.fit(X_train_bin, y_train_bin)\n",
    "\n",
    "# Get the feature coefficients\n",
    "coefficients = ridge_model.coef_\n",
    "\n",
    "# Set a threshold to select features (e.g., absolute coefficient > 0.1)\n",
    "threshold = 0.1\n",
    "ridge_features = X_train_bin.columns[np.abs(coefficients) > threshold]\n",
    "\n",
    "print(f\"Selected features using Ridge regression: {ridge_features}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.4 Random Forest Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=47)\n",
    "\n",
    "# Fit the model on X_train and y_train_encoded\n",
    "rf_model.fit(X_train_bin, y_train_bin)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "important_indices = importances.argsort()[::-1]\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"Feature importances:\", importances)\n",
    "print(\"Sorted feature indices:\", important_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative sum of feature importances\n",
    "cumulative_importance = np.cumsum(importances[important_indices])\n",
    "\n",
    "# Find the index where cumulative importance exceeds 90%\n",
    "threshold = 0.90\n",
    "index_90 = np.argmax(cumulative_importance >= threshold)\n",
    "\n",
    "# The number of features that explain 90% of the importance\n",
    "num_features_90 = index_90 + 1  # Adding 1 since index starts at 0\n",
    "\n",
    "print(f\"Number of features explaining 90% of cumulative importance: {num_features_90}\")\n",
    "\n",
    "# Select the top features based on this number\n",
    "random_forest_features = X_train_bin.columns[important_indices[:num_features_90]]\n",
    "print(f\"Selected features that explain 90% of cumulative importance: {random_forest_features}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.5 Voting of Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all feature sets to sets\n",
    "rfe_set = set(selected_features_rfe)\n",
    "lasso_set = set(lasso_features)\n",
    "ridge_set = set(ridge_features)\n",
    "rf_set = set(random_forest_features)\n",
    "\n",
    "# Find features selected by at least three methods\n",
    "final_features_binary_set = (\n",
    "    (lasso_set & rfe_set & ridge_set) |\n",
    "    (lasso_set & ridge_set & rf_set) |\n",
    "    (ridge_set & rfe_set & rf_set)\n",
    ")\n",
    "\n",
    "# Convert the final features set to a list (optional, for easier use later)\n",
    "final_features_binary = list(final_features_binary_set)\n",
    "\n",
    "# Print the selected features\n",
    "print(len(final_features_binary))\n",
    "print(\"Features selected by at least three methods:\")\n",
    "final_features_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bin_filter = X_train_bin[final_features_binary]\n",
    "X_val_bin_filter = X_val_bin[final_features_binary]\n",
    "X_test_bin_filter = X_test_bin[final_features_binary]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Binary: Model\n",
    "\n",
    ">- Solve classification tasks with two possible outcomes \n",
    ">- Logistic Regression and XGBoost are used, both optimized for binary classification problems\n",
    ">- Accuracy, precision, recall, and F1-score are calculated to assess model performance\n",
    ">- Techniques (SMOTE, Random Under-Sampling) are applied to balance the dataset, ensuring fair representation of both classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model = xgb.XGBClassifier(eval_metric=\"mlogloss\")\n",
    "binary_model.fit(X_train_bin_filter, y_train_bin)\n",
    "\n",
    "# 3. Make predictions\n",
    "y_pred_binary = binary_model.predict(X_val_bin_filter)  # Assuming X_test is available\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val_bin, y_pred_binary)\n",
    "f1_macro = f1_score(y_val_bin, y_pred_binary, average='macro')  # Macro-averaged F1 score\n",
    "\n",
    "# Print individual model results\n",
    "print(f\"XGBClassifier Accuracy: {accuracy:.4f}\")\n",
    "print(f\"XGBClassifier Macro F1 Score: {f1_macro:.4f}\")\n",
    "print(classification_report(y_val_bin, y_pred_binary))  # Detailed report including precision, recall, and F1 score per class\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multiclass: Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Filter Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1 Chi-square & Cramer's V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform Chi-square test\n",
    "# chi2_values, p_values = chi2(X_train_cat, y_train_not_encoded)\n",
    "\n",
    "# # Create DataFrame for Chi-square results\n",
    "# chi2_results = pd.DataFrame({\n",
    "#     'Column': X_train_cat.columns,\n",
    "#     'Chi2': chi2_values.round(5),\n",
    "#     'p-value': p_values.round(5)\n",
    "# })\n",
    "\n",
    "# # Calculate Cramér's V for binary target\n",
    "# cramers_v_values = []\n",
    "# for var in X_train_cat.columns:\n",
    "#     v = cramers_v(X_train_cat[var], y_train_not_encoded)\n",
    "#     cramers_v_values.append(v)\n",
    "\n",
    "# # Add Cramér's V to DataFrame\n",
    "# chi2_results['Cramér\\'s V'] = cramers_v_values\n",
    "\n",
    "# # Filter important features\n",
    "# chi2_important_features = chi2_results[(chi2_results['p-value'] < 0.05) & (chi2_results['Cramér\\'s V'] >= 0.1)]\n",
    "\n",
    "# list_features_chi2_cramer = chi2_important_features['Column'].values\n",
    "\n",
    "# print(chi2_important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2 Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate mutual information for categorical features\n",
    "# mi_scores = mutual_info_classif(X_train_cat, y_train_not_encoded, discrete_features=True)\n",
    "\n",
    "# # Create DataFrame of results\n",
    "# mi_results = pd.DataFrame({\n",
    "#     'Feature': X_train_cat.columns,\n",
    "#     'Mutual Information': mi_scores\n",
    "# }).sort_values(by='Mutual Information', ascending=False)\n",
    "\n",
    "# mi_results\n",
    "\n",
    "# mi_important_features = mi_results[mi_results['Mutual Information'] > 0.05]\n",
    "\n",
    "# list_features_mi = mi_results[mi_results['Mutual Information'] > 0.05]['Feature'].values\n",
    "\n",
    "# print(mi_important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3 Filtered Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select features that appear in at least one of the important feature sets\n",
    "# selected_features = list(set(list_features_chi2_cramer) | set(list_features_mi)) \n",
    "# print(selected_features)\n",
    "\n",
    "# # Keep only selected important features in the datasets\n",
    "# X_train_cat_filtered = X_train_cat[selected_features]\n",
    "# X_val_cat_filtered = X_val_cat[selected_features]\n",
    "# X_test_cat_filtered = X_test_cat[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['COVID-19 Indicator_binary', 'Carrier Type_Self-insured Public Entity', 'Average Weekly Wage_nabinary', 'C-3 Date_nabinary', 'First Hearing Date_nabinary', 'Attorney/Representative_binary']\n",
    "X_train_cat_filtered = X_train_cat[selected_features]\n",
    "X_val_cat_filtered = X_val_cat[selected_features]\n",
    "X_test_cat_filtered = X_test_cat[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Filter Numerical\n",
    ">Numerical features are filtered by evaluating their statistical relevance and correlation to the target variable, ensuring only the most significant features are retained for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.1 Univariate variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_num_scaled.var().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No features with variance zero. Don't drop any here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.2 Spearman Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Spearman correlation matrix for numerical features\n",
    "cor_spearman = X_train_num_scaled.corr(method='spearman')\n",
    "\n",
    "# Flatten the correlation matrix and reset the index\n",
    "correlation_pairs = cor_spearman.unstack().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "correlation_pairs.columns = ['Feature_1', 'Feature_2', 'Correlation']\n",
    "\n",
    "# Filter the table for correlations > 0.8 or < -0.8 and exclude self-correlations (diagonal)\n",
    "strong_correlations = correlation_pairs[\n",
    "    ((correlation_pairs['Correlation'] > 0.9) | (correlation_pairs['Correlation'] < -0.9)) & \n",
    "    (correlation_pairs['Feature_1'] != correlation_pairs['Feature_2'])\n",
    "]\n",
    "\n",
    "# Remove duplicate pairs by keeping only one order\n",
    "strong_correlations = strong_correlations[\n",
    "    strong_correlations['Feature_1'] < strong_correlations['Feature_2']\n",
    "]\n",
    "\n",
    "# Sort by correlation value\n",
    "strong_correlations = strong_correlations.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "# Display the table\n",
    "strong_correlations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.3 Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute mutual information between categorical features and target\n",
    "# mutual_info = mutual_info_classif(X_train_num_scaled, y_train_encoded)\n",
    "\n",
    "# # Display features sorted by mutual information\n",
    "# mi_results = pd.DataFrame({\n",
    "#     'Feature': X_train_num_scaled.columns,\n",
    "#     'Mutual Information': mutual_info\n",
    "# }).sort_values(by='Mutual Information', ascending=False)\n",
    "\n",
    "# mi_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming `mutual_info` is the result from `mutual_info_classif` function\n",
    "# mi_results = pd.DataFrame({\n",
    "#     'Feature': X_train_num_scaled.columns,\n",
    "#     'Mutual Information': mutual_info\n",
    "# }).sort_values(by='Mutual Information', ascending=False)\n",
    "\n",
    "# # Filter features with Mutual Information > 0.05\n",
    "# mi_important_features = mi_results[mi_results['Mutual Information'] > 0.01]\n",
    "\n",
    "# # Display the important features\n",
    "# print(mi_important_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.3 Filtered Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features to drop from X_train_num_scaled\n",
    "num_features_to_drop = [\n",
    "    'Days_between_C-2 Date Imputed_Accident Date_log'\n",
    "    ]\n",
    "\n",
    "# Drop features\n",
    "X_train_num_scaled_filtered = X_train_num_scaled.drop(columns=num_features_to_drop)\n",
    "X_val_num_scaled_filtered = X_val_num_scaled.drop(columns=num_features_to_drop)\n",
    "X_test_num_scaled_filtered = X_test_num_scaled.drop(columns=num_features_to_drop)\n",
    "\n",
    "# Verify the remaining columns\n",
    "print(\"Remaining features in X_train_num_scaled:\", X_train_num_scaled_filtered.columns)\n",
    "print(len(X_train_num_scaled_filtered.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Combine the Filtered Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the filtered datasets\n",
    "X_train = pd.concat([X_train_cat_filtered, X_train_num_scaled_filtered], axis=1)\n",
    "X_val =  pd.concat([X_val_cat_filtered, X_val_num_scaled_filtered], axis=1)\n",
    "X_test =  pd.concat([X_test_cat_filtered, X_test_num_scaled_filtered], axis=1)\n",
    "\n",
    "\n",
    "# Verify the shape of the combined dataset\n",
    "print(\"Shape of combined X_train:\", X_train.shape)\n",
    "print(\"Shape of combined X_train:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Feature Selection All Features\n",
    ">Feature selection is performed using Mutual Information and Recursive Feature Elimination (RFE) to identify the most relevant features for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.1 Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = LassoCV(cv=5)  # Cross-validation to select optimal alpha\n",
    "lasso.fit(X_train, y_train_encoded)\n",
    "lasso_features = X_train.columns[lasso.coef_ != 0]\n",
    "print(\"Selected features by Lasso:\", lasso_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.2 Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ridge regression model with cross-validation\n",
    "ridge_model = RidgeCV(cv=5)\n",
    "\n",
    "# Fit the model on the training data\n",
    "ridge_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Get the feature coefficients\n",
    "coefficients = ridge_model.coef_\n",
    "\n",
    "# Set a threshold to select features (e.g., absolute coefficient > 0.01)\n",
    "threshold = 0.01\n",
    "ridge_features = X_train.columns[np.abs(coefficients) > threshold]\n",
    "\n",
    "print(f\"Selected features using Ridge regression: {ridge_features}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=47)\n",
    "\n",
    "# Fit the model on X_train and y_train_encoded\n",
    "rf_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "important_indices = importances.argsort()[::-1]\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"Feature importances:\", importances)\n",
    "print(\"Sorted feature indices:\", important_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative sum of feature importances\n",
    "cumulative_importance = np.cumsum(importances[important_indices])\n",
    "\n",
    "# Find the index where cumulative importance exceeds 90%\n",
    "threshold = 0.90\n",
    "index_90 = np.argmax(cumulative_importance >= threshold)\n",
    "\n",
    "# The number of features that explain 90% of the importance\n",
    "num_features_90 = index_90 + 1  # Adding 1 since index starts at 0\n",
    "\n",
    "print(f\"Number of features explaining 90% of cumulative importance: {num_features_90}\")\n",
    "\n",
    "# Select the top features based on this number\n",
    "random_forest_features = X_train.columns[important_indices[:num_features_90]]\n",
    "print(f\"Selected features that explain 90% of cumulative importance: {random_forest_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost Classifier without 'use_label_encoder'\n",
    "xgb_model = XGBClassifier(n_estimators=100, random_state=47, eval_metric=\"mlogloss\")\n",
    "\n",
    "# Fit the model on X_train and y_train_encoded\n",
    "xgb_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Get feature importances\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame with feature names and their importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,  # Assumes X_train is a pandas DataFrame\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the sorted feature names and their importance\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative sum of feature importances\n",
    "cumulative_importance = np.cumsum(feature_importance_df['Importance'])\n",
    "\n",
    "# Find the index where cumulative importance exceeds 90%\n",
    "threshold = 0.90\n",
    "index_90 = np.argmax(cumulative_importance >= threshold)\n",
    "\n",
    "# The number of features that explain 90% of the importance\n",
    "num_features_90 = index_90 + 1  # Adding 1 since index starts at 0\n",
    "\n",
    "print(f\"Number of features explaining 90% of cumulative importance: {num_features_90}\")\n",
    "\n",
    "# Select the top features based on this number\n",
    "xgboost_features = feature_importance_df['Feature'].iloc[:num_features_90]\n",
    "print(f\"Selected features that explain 90% of cumulative importance:\\n{xgboost_features}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.5 Voting for the Best Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all feature sets to sets\n",
    "lasso_set = set(lasso_features)\n",
    "ridge_set = set(ridge_features)\n",
    "rf_set = set(random_forest_features)\n",
    "xgb_set = set(xgboost_features)\n",
    "\n",
    "# Find features selected by at least three methods\n",
    "final_features_set = (\n",
    "    (lasso_set & ridge_set & rf_set) |  # Features in all three: Lasso, Ridge, RF\n",
    "    (lasso_set & ridge_set & xgb_set) |  # Features in Lasso, Ridge, XGBoost\n",
    "    (lasso_set & rf_set & xgb_set) |     # Features in Lasso, RF, XGBoost\n",
    "    (ridge_set & rf_set & xgb_set)      # Features in Ridge, RF, XGBoost\n",
    ")\n",
    "\n",
    "# Convert the final features set to a list (optional, for easier use later)\n",
    "final_features = list(final_features_set)\n",
    "\n",
    "# Print the selected features\n",
    "print(len(final_features))\n",
    "print(\"Features selected by at least three methods:\")\n",
    "print(final_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Apply to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the following sets represent the selected features from each method\n",
    "lasso_set = set(lasso_features)\n",
    "ridge_set = set(ridge_features)\n",
    "rf_set = set(random_forest_features)\n",
    "xgb_set = set(xgboost_features)\n",
    "\n",
    "# Combine all unique features from all sets\n",
    "all_features = list(set(lasso_set) | set(ridge_set) | set(rf_set) | set(xgb_set))\n",
    "\n",
    "# Create a DataFrame to show the feature selection results\n",
    "feature_selection_table = pd.DataFrame({\n",
    "    'Feature': all_features,\n",
    "    'Lasso': [feature in lasso_set for feature in all_features],\n",
    "    'Ridge': [feature in ridge_set for feature in all_features],\n",
    "    'Random Forest': [feature in rf_set for feature in all_features],\n",
    "    'XGBoost': [feature in xgb_set for feature in all_features]\n",
    "})\n",
    "\n",
    "# Add a column to count how many methods selected each feature\n",
    "feature_selection_table['Selected by 2 or more'] = (\n",
    "    feature_selection_table[['Lasso', 'Ridge', 'Random Forest', 'XGBoost']].sum(axis=1) >= 3\n",
    ")\n",
    "\n",
    "# Extract lists of features selected by each method\n",
    "lasso_selected_features = feature_selection_table[feature_selection_table['Lasso']]['Feature'].tolist()\n",
    "ridge_selected_features = feature_selection_table[feature_selection_table['Ridge']]['Feature'].tolist()\n",
    "rf_selected_features = feature_selection_table[feature_selection_table['Random Forest']]['Feature'].tolist()\n",
    "xgb_selected_features = feature_selection_table[feature_selection_table['XGBoost']]['Feature'].tolist()\n",
    "\n",
    "# Extract features selected by 3 or more methods\n",
    "selected_by_3_or_more = feature_selection_table[feature_selection_table['Selected by 2 or more']]['Feature'].tolist()\n",
    "\n",
    "# Function to highlight selected features for Lasso, Ridge, RF, and XGBoost\n",
    "def highlight_selected(val):\n",
    "    return 'background-color: #aed6f1' if val else ''\n",
    "\n",
    "def highlight_selected_by_3_or_more(val):\n",
    "    return 'background-color: #abebc6' if val else ''\n",
    "\n",
    "# Apply the styling to each column using apply and map\n",
    "styled_table = feature_selection_table.style.apply(\n",
    "    lambda x: ['background-color: #aed6f1' if val else '' for val in x], \n",
    "    subset=['Lasso', 'Ridge', 'Random Forest', 'XGBoost']\n",
    ").apply(\n",
    "    lambda x: ['background-color: #abebc6' if val else '' for val in x], \n",
    "    subset=['Selected by 2 or more']\n",
    ")\n",
    "\n",
    "# Display the styled table\n",
    "styled_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_by_3_or_more = ['Accident Datemonth',\n",
    " 'Industry Code_encoded_4. TEMPORARY',\n",
    " 'WCIO Part Of Body Code_encoded_5. PPD SCH LOSS',\n",
    " 'Average Weekly Wage Imputed_log',\n",
    " 'C-3 Date_nabinary',\n",
    " 'WCIO Cause of Injury Code_encoded_3. MED ONLY',\n",
    " 'COVID-19 Indicator_binary',\n",
    " 'Industry Code_encoded_3. MED ONLY',\n",
    " 'Age at Injury',\n",
    " 'WCIO Part Of Body Code_freq',\n",
    " 'WCIO Cause of Injury Code_freq',\n",
    " 'WCIO Nature of Injury Code_encoded_5. PPD SCH LOSS',\n",
    " 'IME-4 Count',\n",
    " 'WCIO Cause of Injury Code_encoded_1. CANCELLED',\n",
    " 'WCIO Cause of Injury Code_encoded_6. PPD NSL',\n",
    " 'WCIO Part Of Body Code_encoded_4. TEMPORARY',\n",
    " 'WCIO Cause of Injury Code_encoded_4. TEMPORARY',\n",
    " 'WCIO Nature of Injury Code_encoded_1. CANCELLED',\n",
    " 'Industry Code_freq',\n",
    " 'Days_between_Assembly Date_Accident Date_log',\n",
    " 'WCIO Part Of Body Code_encoded_8. DEATH',\n",
    " 'WCIO Cause of Injury Code_encoded_5. PPD SCH LOSS',\n",
    " 'Carrier Type_Self-insured Public Entity',\n",
    " 'Carrier Name_freq',\n",
    " 'WCIO Nature of Injury Code_encoded_3. MED ONLY',\n",
    " 'Average Weekly Wage_nabinary',\n",
    " 'Carrier Type Imputed_freq',\n",
    " 'Attorney/Representative_binary',\n",
    " 'WCIO Part Of Body Code_encoded_6. PPD NSL',\n",
    " 'First Hearing Date_nabinary',\n",
    " 'Industry Code_encoded_1. CANCELLED',\n",
    " 'WCIO Part Of Body Code_encoded_3. MED ONLY',\n",
    " 'WCIO Nature of Injury Code_encoded_6. PPD NSL',\n",
    " 'WCIO Nature of Injury Code_encoded_4. TEMPORARY',\n",
    " 'Industry Code_encoded_5. PPD SCH LOSS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filter = X_train[selected_by_3_or_more]\n",
    "X_val_filter = X_val[selected_by_3_or_more]\n",
    "X_test_filter = X_test[selected_by_3_or_more]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multiclass Model\n",
    "\n",
    ">Random Forest, XGBoost, and Ridge Classifier to predict target variables with multiple categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `y` is your target variable\n",
    "class_distribution = y_train_encoded.value_counts()\n",
    "class_percentages = y_train_encoded.value_counts(normalize=True) * 100\n",
    "\n",
    "# Combine into a single DataFrame for better visualization\n",
    "distribution_df = pd.DataFrame({\n",
    "    'Class': class_distribution.index,\n",
    "    'Count': class_distribution.values,\n",
    "    'Percentage (%)': class_percentages.values\n",
    "})\n",
    "print(distribution_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define undersampling strategy based on the actual class distribution\n",
    "undersample_strategy = {\n",
    "    0: 50621,\n",
    "    2: 47591,\n",
    "    1: 33513,\n",
    "    4: 8191,\n",
    "    4: 2924,\n",
    "    5: 324,\n",
    "    6:67\n",
    "}\n",
    "\n",
    "# Apply undersampling to majority classes\n",
    "undersampler = RandomUnderSampler(sampling_strategy=undersample_strategy, random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X_train_filter, y_train_encoded)\n",
    "\n",
    "# # Define SMOTE strategy for oversampling the minority classes\n",
    "# smote = SMOTE(sampling_strategy={\n",
    "#     7:807,\n",
    "\n",
    "#     6: 670,   # Oversample class '5' to 3,000\n",
    "# }, random_state=42)\n",
    "\n",
    "# # Apply SMOTE to oversample minority classes\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "# Check the new class distribution after resampling\n",
    "unique_classes_final, class_counts_final = np.unique(y_resampled, return_counts=True)\n",
    "class_distribution_final = dict(zip(unique_classes_final, class_counts_final))\n",
    "print(\"New Class Distribution after Resampling:\", class_distribution_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = np.ones(len(y_train_encoded))\n",
    "# weights[y_train_encoded == 0] = 10\n",
    "\n",
    "\n",
    "weights = np.ones(len(y_resampled))\n",
    "weights[y_resampled == 0] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_model = xgb.XGBClassifier(eval_metric=\"mlogloss\")\n",
    "# multiclass_model.fit(X_train_filter, y_train_encoded, sample_weight=weights)\n",
    "multiclass_model.fit(X_resampled, y_resampled, sample_weight=weights)\n",
    "\n",
    "# 3. Make predictions\n",
    "y_pred = multiclass_model.predict(X_val_filter)  # Assuming X_test is available\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val_encoded, y_pred)\n",
    "f1_macro = f1_score(y_val_encoded, y_pred, average='macro')  # Macro-averaged F1 score\n",
    "\n",
    "# Print individual model results\n",
    "print(f\"XGBClassifier Accuracy: {accuracy:.4f}\")\n",
    "print(f\"XGBClassifier Macro F1 Score: {f1_macro:.4f}\")\n",
    "print(classification_report(y_val_encoded, y_pred))  # Detailed report including precision, recall, and F1 score per class\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Two-stage Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for binary classification (whether it's non-comp or not)\n",
    "y_proba_binary = stacking_model.predict(X_test_bin_filter)\n",
    "\n",
    "# y_proba_binary = binary_model.predict(xgb.DMatrix(X_test_bin_filter))\n",
    "\n",
    "# Convert probabilities to binary predictions (0 for not non-comp, 1 for non-comp)\n",
    "threshold = 0.5  # Default threshold, you can adjust based on recall\n",
    "y_pred_binary = (y_proba_binary > threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of instances predicted as not non-comp (i.e., predicted as 0)\n",
    "non_com =  (y_pred_binary == 1)\n",
    "not_non_comp_indices = (y_pred_binary == 0)\n",
    "\n",
    "# Use these indices to filter `X_val_filter` to get the corresponding instances\n",
    "X_test_filtered_for_multiclass = X_test_filter[not_non_comp_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict multiclass labels for the filtered data (instances not predicted as non-comp)\n",
    "y_pred_multiclass = multiclass_model.predict(X_test_filtered_for_multiclass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_test_filtered_for_multiclass is a DataFrame, and y_pred_multiclass are the predictions\n",
    "X_test_filtered_for_multiclass.loc[:, 'predictions'] = y_pred_multiclass\n",
    "\n",
    "# Now you have a DataFrame with the original features and the predictions as a new column\n",
    "X_test_filtered_for_multiclass.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the filtered dataset (i.e., the rows of X_test that were used for multiclass prediction)\n",
    "filtered_indices = X_test_filtered_for_multiclass.index\n",
    "\n",
    "# Now, you can map the predictions back to the original dataset by creating a new column in the original DataFrame\n",
    "X_test.loc[filtered_indices, 'predictions'] = y_pred_multiclass\n",
    "\n",
    "# Now you have the predictions in the original dataset at the corresponding rows\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the distribution of predicted classes\n",
    "predictions_df = pd.DataFrame(y_pred_multiclass, columns=[\"Predicted Label\"])\n",
    "print(\"Predicted Class Distribution:\")\n",
    "print(predictions_df[\"Predicted Label\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_injury_type_mapping = {\n",
    "    '4. TEMPORARY': 0,\n",
    "    '5. PPD SCH LOSS': 1,\n",
    "    '3. MED ONLY': 2,\n",
    "    '6. PPD NSL': 3,\n",
    "    '1. CANCELLED': 4,\n",
    "    '8. DEATH': 5,\n",
    "    '7. PTD': 6\n",
    "}\n",
    "\n",
    "\n",
    "# Reverse the mapping\n",
    "reverse_claim_injury_type_mapping = {v: k for k, v in claim_injury_type_mapping.items()}\n",
    "\n",
    "# Use the reversed mapping to get the original labels\n",
    "X_test['predictions'] = X_test['predictions'].map(reverse_claim_injury_type_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in the 'predictions' column with the value '2. NON-COMP'\n",
    "X_test['predictions'] = X_test['predictions'].fillna('2. NON-COMP')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['predictions'].to_csv('test_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project-7bptfTa5-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
