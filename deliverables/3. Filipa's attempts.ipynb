{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467cffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    " #Correlation Heatmap\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "#Statistical Test\n",
    "from scipy import stats\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "707be7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can download the data in the source that is linked above the table of contents\n",
    "\n",
    "# Read in the data\n",
    "X_val_encoded = pd.read_csv('../project_data/X_val_encoded.csv', delimiter=',', index_col=0)\n",
    "X_train_encoded = pd.read_csv('../project_data/X_train_encoded.csv', delimiter=',', index_col=0)\n",
    "\n",
    "y_train = pd.read_csv('../project_data/y_train.csv',delimiter=',', index_col=0)\n",
    "y_val= pd.read_csv('../project_data/y_val.csv', delimiter=',', index_col=0)\n",
    "\n",
    "X_test_encoded = pd.read_csv('../project_data/X_test_encoded.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b0f7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382537\n",
      "382537\n"
     ]
    }
   ],
   "source": [
    "#NEW: just to check the shape\n",
    "print(X_train_encoded.shape[0])\n",
    "print(y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be5545a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_injury_type_mapping = {\n",
    "    '4. TEMPORARY': 4,\n",
    "    '2. NON-COMP': 2,\n",
    "    '5. PPD SCH LOSS': 5,\n",
    "    '3. MED ONLY': 3,\n",
    "    '6. PPD NSL': 6,\n",
    "    '1. CANCELLED': 1,\n",
    "    '8. DEATH': 8,\n",
    "    '7. PTD': 7\n",
    "}\n",
    "\n",
    "y_train_encoded = y_train['Claim Injury Type'].map(claim_injury_type_mapping)\n",
    "y_val_encoded = y_val['Claim Injury Type'].map(claim_injury_type_mapping)\n",
    "#NEW\n",
    "y_train_encoded = pd.DataFrame(y_train_encoded, columns=['Claim Injury Type'])\n",
    "y_val_encoded = pd.DataFrame(y_val_encoded, columns=['Claim Injury Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70840467",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = ['Age at Injury', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'Number of Dependents', 'Days_between_Acc_Assembyl']\n",
    "\n",
    "cat_columns = ['Alternative Dispute Resolution', 'Attorney/Representative', 'C-2 Date', 'C-3 Date', 'COVID-19 Indicator', 'Gender','First Hearing Date',\n",
    "               'CarrierGroup_Self-insured Private Entity', 'CarrierGroup_Self-insured Public Entity', 'CarrierGroup_Special Funds',\n",
    "               'CarrierGroup_State Insurance Fund', 'Industry Code_encoded_5. PPD SCH LOSS', 'Industry Code_encoded_2. NON-COMP', \n",
    "               'Industry Code_encoded_3. MED ONLY', 'Industry Code_encoded_4. TEMPORARY', 'Industry Code_encoded_1. CANCELLED', \n",
    "               'Industry Code_encoded_8. DEATH', 'Industry Code_encoded_6. PPD NSL', 'Industry Code_encoded_7. PTD',\n",
    "               'Injury_Cause_Category_encoded_5. PPD SCH LOSS', 'Injury_Cause_Category_encoded_2. NON-COMP', \n",
    "               'Injury_Cause_Category_encoded_3. MED ONLY', 'Injury_Cause_Category_encoded_4. TEMPORARY', \n",
    "               'Injury_Cause_Category_encoded_1. CANCELLED', 'Injury_Cause_Category_encoded_8. DEATH','Injury_Cause_Category_encoded_6. PPD NSL',\n",
    "                'Injury_Cause_Category_encoded_7. PTD', 'Nature_Injury_Occupational', 'Nature_Injury_Specific', 'Nature_Injury_Unknown',\n",
    "                'Part_Body_Category_encoded_5. PPD SCH LOSS', 'Part_Body_Category_encoded_2. NON-COMP', 'Part_Body_Category_encoded_3. MED ONLY',\n",
    "                'Part_Body_Category_encoded_4. TEMPORARY', 'Part_Body_Category_encoded_1. CANCELLED', 'Part_Body_Category_encoded_8. DEATH',\n",
    "                'Part_Body_Category_encoded_6. PPD NSL', 'Part_Body_Category_encoded_7. PTD']\n",
    "\n",
    "\n",
    "# Create subsets\n",
    "X_train_num = X_train_encoded[num_columns]\n",
    "X_train_cat = X_train_encoded[cat_columns]\n",
    "\n",
    "X_val_num = X_val_encoded[num_columns]\n",
    "X_val_cat = X_val_encoded[cat_columns]\n",
    "\n",
    "X_test_num=X_test_encoded[num_columns]\n",
    "X_test_cat=X_test_encoded[cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae751336",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(X_train_num)\n",
    "X_train_num_scaled = scaler.transform(X_train_num)\n",
    "\n",
    "# Convert the array to a pandas dataframe\n",
    "X_train_num_scaled = pd.DataFrame(X_train_num_scaled, columns = X_train_num.columns).set_index(X_train_encoded.index)\n",
    "X_val_num_scaled = scaler.transform(X_val_num)\n",
    "\n",
    "X_test_num_scaled = scaler.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d763ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remerge the numerical and categorical features\n",
    "X_train = pd.concat([X_train_num[['IME-4 Count']], X_train_cat], axis=1)\n",
    "X_val = pd.concat([X_val_num[['IME-4 Count']], X_val_cat], axis=1)\n",
    "X_test =pd.concat([X_test_num[['IME-4 Count']], X_test_cat], axis=1)\n",
    "y_train=y_train_encoded.copy()\n",
    "y_val=y_val_encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28ec9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform into a series\n",
    "y_train = y_train.squeeze()\n",
    "y_val = y_val.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c6e52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.5.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\utilizador\\appdata\\roaming\\python\\python312\\site-packages (from lightgbm) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\utilizador\\appdata\\roaming\\python\\python312\\site-packages (from lightgbm) (1.14.1)\n",
      "Downloading lightgbm-4.5.0-py3-none-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 0.8/1.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 4.0 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677a5e4a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2702c45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training and Evaluating: Logistic Regression\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.43      0.52      7701\n",
      "           2       0.71      0.94      0.81    200073\n",
      "           3       0.30      0.01      0.01     46185\n",
      "           4       0.57      0.53      0.55     95874\n",
      "           5       0.53      0.40      0.45     29651\n",
      "           6       0.00      0.00      0.00      2721\n",
      "           7       0.00      0.00      0.00        57\n",
      "           8       0.27      0.06      0.10       275\n",
      "\n",
      "    accuracy                           0.67    382537\n",
      "   macro avg       0.38      0.30      0.31    382537\n",
      "weighted avg       0.61      0.67      0.61    382537\n",
      "\n",
      "Confusion Matrix (Train):\n",
      " [[  3307   3324     26    815    226      0      0      3]\n",
      " [  1499 188290    241   7825   2205      0      0     13]\n",
      " [    50  31188    354  11884   2706      0      0      3]\n",
      " [    44  39143    448  50937   5274      0      0     28]\n",
      " [    11   2545     92  15175  11828      0      0      0]\n",
      " [     0     12     22   2462    225      0      0      0]\n",
      " [     1      0      0     54      2      0      0      0]\n",
      " [     3     69      8    175      3      0      0     17]]\n",
      "\n",
      "F1 Macro Score (Train): 0.3067390527176675\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.44      0.53      3263\n",
      "           2       0.71      0.94      0.81     85765\n",
      "           3       0.29      0.01      0.01     19810\n",
      "           4       0.57      0.53      0.55     41064\n",
      "           5       0.53      0.39      0.45     12669\n",
      "           6       0.00      0.00      0.00      1167\n",
      "           7       0.00      0.00      0.00        24\n",
      "           8       0.38      0.09      0.14       123\n",
      "\n",
      "    accuracy                           0.67    163885\n",
      "   macro avg       0.39      0.30      0.31    163885\n",
      "weighted avg       0.60      0.67      0.61    163885\n",
      "\n",
      "Confusion Matrix (Validation):\n",
      " [[ 1431  1368     4   366    94     0     0     0]\n",
      " [  633 80694   100  3350   985     0     0     3]\n",
      " [   26 13311   150  5154  1165     0     0     4]\n",
      " [   19 16778   215 21885  2156     0     0    11]\n",
      " [    4  1106    47  6529  4983     0     0     0]\n",
      " [    0     6     3  1081    77     0     0     0]\n",
      " [    0     0     0    23     1     0     0     0]\n",
      " [    2    27     4    78     1     0     0    11]]\n",
      "\n",
      "F1 Macro Score (Validation): 0.3128883850064663\n",
      "\n",
      "==================================================\n",
      "Training and Evaluating: Neural Network\n",
      "==================================================\n",
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.48      0.56      7701\n",
      "           2       0.72      0.94      0.82    200073\n",
      "           3       0.47      0.02      0.04     46185\n",
      "           4       0.58      0.57      0.58     95874\n",
      "           5       0.61      0.43      0.50     29651\n",
      "           6       0.00      0.00      0.00      2721\n",
      "           7       0.00      0.00      0.00        57\n",
      "           8       0.43      0.26      0.33       275\n",
      "\n",
      "    accuracy                           0.68    382537\n",
      "   macro avg       0.44      0.34      0.35    382537\n",
      "weighted avg       0.64      0.68      0.63    382537\n",
      "\n",
      "Confusion Matrix (Train):\n",
      " [[  3673   3038     25    861     98      0      0      6]\n",
      " [  1493 188824    330   8161   1234      0      0     31]\n",
      " [    51  30476    917  12509   2220      0      0     12]\n",
      " [    85  36296    581  54424   4443      0      0     45]\n",
      " [    35   2349    103  14435  12729      0      0      0]\n",
      " [     0     20      3   2517    181      0      0      0]\n",
      " [     0      0      0     55      2      0      0      0]\n",
      " [     4     45      4    150      0      0      0     72]]\n",
      "\n",
      "F1 Macro Score (Train): 0.3532944078089757\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.48      0.56      3263\n",
      "           2       0.72      0.94      0.82     85765\n",
      "           3       0.44      0.02      0.04     19810\n",
      "           4       0.58      0.57      0.58     41064\n",
      "           5       0.61      0.42      0.50     12669\n",
      "           6       0.00      0.00      0.00      1167\n",
      "           7       0.00      0.00      0.00        24\n",
      "           8       0.41      0.23      0.29       123\n",
      "\n",
      "    accuracy                           0.68    163885\n",
      "   macro avg       0.43      0.33      0.35    163885\n",
      "weighted avg       0.64      0.68      0.63    163885\n",
      "\n",
      "Confusion Matrix (Validation):\n",
      " [[ 1558  1264    12   383    42     0     0     4]\n",
      " [  622 80896   155  3518   564     0     0    10]\n",
      " [   32 13058   379  5384   951     0     0     6]\n",
      " [   37 15495   272 23377  1863     0     0    20]\n",
      " [   19  1017    36  6234  5363     0     0     0]\n",
      " [    0     5     3  1099    60     0     0     0]\n",
      " [    0     0     0    23     1     0     0     0]\n",
      " [    3    25     0    66     1     0     0    28]]\n",
      "\n",
      "F1 Macro Score (Validation): 0.3483434719716329\n",
      "\n",
      "==================================================\n",
      "Training and Evaluating: Random Forest\n",
      "==================================================\n",
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.54      0.63      7701\n",
      "           2       0.75      0.95      0.84    200073\n",
      "           3       0.66      0.19      0.30     46185\n",
      "           4       0.72      0.60      0.65     95874\n",
      "           5       0.70      0.67      0.68     29651\n",
      "           6       0.84      0.31      0.45      2721\n",
      "           7       0.89      0.56      0.69        57\n",
      "           8       0.73      0.61      0.67       275\n",
      "\n",
      "    accuracy                           0.74    382537\n",
      "   macro avg       0.75      0.55      0.61    382537\n",
      "weighted avg       0.73      0.74      0.71    382537\n",
      "\n",
      "Confusion Matrix (Train):\n",
      " [[  4148   2764    161    514    112      0      0      2]\n",
      " [  1180 190307   1529   5865   1176      3      1     12]\n",
      " [    71  27259   8967   7558   2290     28      0     12]\n",
      " [   119  31615   2109  57058   4861     80      2     30]\n",
      " [    28   1888    788   6925  19975     44      0      3]\n",
      " [     0     26     64   1514    281    833      1      2]\n",
      " [     0      2      1     20      2      0     32      0]\n",
      " [     0     30     23     52      1      0      0    169]]\n",
      "\n",
      "F1 Macro Score (Train): 0.6133063835157717\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.46      0.53      3263\n",
      "           2       0.73      0.92      0.81     85765\n",
      "           3       0.26      0.07      0.11     19810\n",
      "           4       0.58      0.49      0.53     41064\n",
      "           5       0.51      0.49      0.50     12669\n",
      "           6       0.07      0.02      0.03      1167\n",
      "           7       0.00      0.00      0.00        24\n",
      "           8       0.20      0.11      0.15       123\n",
      "\n",
      "    accuracy                           0.66    163885\n",
      "   macro avg       0.37      0.32      0.33    163885\n",
      "weighted avg       0.61      0.66      0.62    163885\n",
      "\n",
      "Confusion Matrix (Validation):\n",
      " [[ 1494  1278    85   323    81     0     0     2]\n",
      " [  629 79248  1227  3893   749     6     0    13]\n",
      " [   73 12349  1448  4601  1294    30     2    13]\n",
      " [  124 14801  2031 20264  3606   201    11    26]\n",
      " [   31  1053   634  4703  6211    37     0     0]\n",
      " [    1     8    45   952   140    21     0     0]\n",
      " [    0     0     0    20     2     1     0     1]\n",
      " [    2    36    12    58     0     1     0    14]]\n",
      "\n",
      "F1 Macro Score (Validation): 0.3339612886975133\n",
      "\n",
      "==================================================\n",
      "Training and Evaluating: Decision Tree\n",
      "==================================================\n",
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.58      0.64      7701\n",
      "           2       0.74      0.96      0.84    200073\n",
      "           3       0.63      0.21      0.32     46185\n",
      "           4       0.73      0.58      0.65     95874\n",
      "           5       0.73      0.62      0.67     29651\n",
      "           6       0.95      0.27      0.42      2721\n",
      "           7       0.97      0.51      0.67        57\n",
      "           8       0.87      0.51      0.65       275\n",
      "\n",
      "    accuracy                           0.74    382537\n",
      "   macro avg       0.79      0.53      0.61    382537\n",
      "weighted avg       0.73      0.74      0.71    382537\n",
      "\n",
      "Confusion Matrix (Train):\n",
      " [[  4466   2617    119    415     84      0      0      0]\n",
      " [  1369 191881   1070   4831    919      0      0      3]\n",
      " [   153  28030   9767   6357   1870      5      0      3]\n",
      " [   228  32831   3105  55964   3706     26      1     13]\n",
      " [    61   2188   1179   7715  18501      6      0      1]\n",
      " [     2     39    114   1555    269    741      0      1]\n",
      " [     0      4      0     21      2      1     29      0]\n",
      " [     2     43     32     57      0      0      0    141]]\n",
      "\n",
      "F1 Macro Score (Train): 0.606305457131044\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.48      0.51      3263\n",
      "           2       0.72      0.93      0.81     85765\n",
      "           3       0.24      0.08      0.12     19810\n",
      "           4       0.59      0.46      0.52     41064\n",
      "           5       0.52      0.46      0.49     12669\n",
      "           6       0.10      0.03      0.05      1167\n",
      "           7       0.00      0.00      0.00        24\n",
      "           8       0.18      0.11      0.14       123\n",
      "\n",
      "    accuracy                           0.66    163885\n",
      "   macro avg       0.36      0.32      0.33    163885\n",
      "weighted avg       0.61      0.66      0.62    163885\n",
      "\n",
      "Confusion Matrix (Validation):\n",
      " [[ 1550  1244   103   289    74     1     0     2]\n",
      " [  779 79557  1297  3427   674     8     3    20]\n",
      " [  136 12641  1624  4158  1206    28     2    15]\n",
      " [  235 15490  2842 18923  3248   278    22    26]\n",
      " [   64  1250   892  4595  5821    45     1     1]\n",
      " [    6    15    76   895   135    40     0     0]\n",
      " [    0     2     2    16     2     2     0     0]\n",
      " [    5    40    15    43     2     3     1    14]]\n",
      "\n",
      "F1 Macro Score (Validation): 0.33016134284356835\n",
      "\n",
      "==================================================\n",
      "Training and Evaluating: SVM (RBF Kernel)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "# Function to calculate and print metrics\n",
    "def metrics(y_train, pred_train, y_val, pred_val):\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                     TRAIN                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    print('Confusion Matrix (Train):\\n', confusion_matrix(y_train, pred_train))\n",
    "    print('\\nF1 Macro Score (Train):', f1_score(y_train, pred_train, average='macro'))\n",
    "\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                VALIDATION                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_val, pred_val))\n",
    "    print('Confusion Matrix (Validation):\\n', confusion_matrix(y_val, pred_val))\n",
    "    print('\\nF1 Macro Score (Validation):', f1_score(y_val, pred_val, average='macro'))\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500, random_state=42),\n",
    "    \"Neural Network\": MLPClassifier(max_iter=500, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"SVM (RBF Kernel)\": SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    #\"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    #\"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "    \"Ridge Classifier\": RidgeClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\\nTraining and Evaluating: {model_name}\\n{'='*50}\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Print metrics\n",
    "    metrics(y_train, pred_train, y_val, pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba5994b",
   "metadata": {},
   "source": [
    "==================================================\n",
    "Training and Evaluating: Logistic Regression\n",
    "==================================================\n",
    "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  n_iter_i = _check_optimize_result(\n",
    "___________________________________________________________________________________________________________\n",
    "                                                     TRAIN                                                 \n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.67      0.43      0.52      7701\n",
    "           2       0.71      0.94      0.81    200073\n",
    "           3       0.30      0.01      0.01     46185\n",
    "           4       0.57      0.53      0.55     95874\n",
    "           5       0.53      0.40      0.45     29651\n",
    "           6       0.00      0.00      0.00      2721\n",
    "           7       0.00      0.00      0.00        57\n",
    "           8       0.27      0.06      0.10       275\n",
    "\n",
    "    accuracy                           0.67    382537\n",
    "   macro avg       0.38      0.30      0.31    382537\n",
    "weighted avg       0.61      0.67      0.61    382537\n",
    "\n",
    "Confusion Matrix (Train):\n",
    " [[  3307   3324     26    815    226      0      0      3]\n",
    " [  1499 188290    241   7825   2205      0      0     13]\n",
    " [    50  31188    354  11884   2706      0      0      3]\n",
    " [    44  39143    448  50937   5274      0      0     28]\n",
    " [    11   2545     92  15175  11828      0      0      0]\n",
    " [     0     12     22   2462    225      0      0      0]\n",
    " [     1      0      0     54      2      0      0      0]\n",
    " [     3     69      8    175      3      0      0     17]]\n",
    "\n",
    "F1 Macro Score (Train): 0.3067390527176675\n",
    "___________________________________________________________________________________________________________\n",
    "                                                VALIDATION                                                 \n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.68      0.44      0.53      3263\n",
    "           2       0.71      0.94      0.81     85765\n",
    "           3       0.29      0.01      0.01     19810\n",
    "           4       0.57      0.53      0.55     41064\n",
    "           5       0.53      0.39      0.45     12669\n",
    "           6       0.00      0.00      0.00      1167\n",
    "           7       0.00      0.00      0.00        24\n",
    "           8       0.38      0.09      0.14       123\n",
    "\n",
    "    accuracy                           0.67    163885\n",
    "   macro avg       0.39      0.30      0.31    163885\n",
    "weighted avg       0.60      0.67      0.61    163885\n",
    "\n",
    "Confusion Matrix (Validation):\n",
    " [[ 1431  1368     4   366    94     0     0     0]\n",
    " [  633 80694   100  3350   985     0     0     3]\n",
    " [   26 13311   150  5154  1165     0     0     4]\n",
    " [   19 16778   215 21885  2156     0     0    11]\n",
    " [    4  1106    47  6529  4983     0     0     0]\n",
    " [    0     6     3  1081    77     0     0     0]\n",
    " [    0     0     0    23     1     0     0     0]\n",
    " [    2    27     4    78     1     0     0    11]]\n",
    "\n",
    "F1 Macro Score (Validation): 0.3128883850064663\n",
    "\n",
    "==================================================\n",
    "Training and Evaluating: Neural Network\n",
    "==================================================\n",
    "___________________________________________________________________________________________________________\n",
    "                                                     TRAIN                                                 \n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.69      0.48      0.56      7701\n",
    "           2       0.72      0.94      0.82    200073\n",
    "           3       0.47      0.02      0.04     46185\n",
    "           4       0.58      0.57      0.58     95874\n",
    "           5       0.61      0.43      0.50     29651\n",
    "           6       0.00      0.00      0.00      2721\n",
    "           7       0.00      0.00      0.00        57\n",
    "           8       0.43      0.26      0.33       275\n",
    "\n",
    "    accuracy                           0.68    382537\n",
    "   macro avg       0.44      0.34      0.35    382537\n",
    "weighted avg       0.64      0.68      0.63    382537\n",
    "\n",
    "Confusion Matrix (Train):\n",
    " [[  3673   3038     25    861     98      0      0      6]\n",
    " [  1493 188824    330   8161   1234      0      0     31]\n",
    " [    51  30476    917  12509   2220      0      0     12]\n",
    " [    85  36296    581  54424   4443      0      0     45]\n",
    " [    35   2349    103  14435  12729      0      0      0]\n",
    " [     0     20      3   2517    181      0      0      0]\n",
    " [     0      0      0     55      2      0      0      0]\n",
    " [     4     45      4    150      0      0      0     72]]\n",
    "\n",
    "F1 Macro Score (Train): 0.3532944078089757\n",
    "___________________________________________________________________________________________________________\n",
    "                                                VALIDATION                                                 \n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.69      0.48      0.56      3263\n",
    "           2       0.72      0.94      0.82     85765\n",
    "           3       0.44      0.02      0.04     19810\n",
    "           4       0.58      0.57      0.58     41064\n",
    "           5       0.61      0.42      0.50     12669\n",
    "           6       0.00      0.00      0.00      1167\n",
    "           7       0.00      0.00      0.00        24\n",
    "           8       0.41      0.23      0.29       123\n",
    "\n",
    "    accuracy                           0.68    163885\n",
    "   macro avg       0.43      0.33      0.35    163885\n",
    "weighted avg       0.64      0.68      0.63    163885\n",
    "\n",
    "Confusion Matrix (Validation):\n",
    " [[ 1558  1264    12   383    42     0     0     4]\n",
    " [  622 80896   155  3518   564     0     0    10]\n",
    " [   32 13058   379  5384   951     0     0     6]\n",
    " [   37 15495   272 23377  1863     0     0    20]\n",
    " [   19  1017    36  6234  5363     0     0     0]\n",
    " [    0     5     3  1099    60     0     0     0]\n",
    " [    0     0     0    23     1     0     0     0]\n",
    " [    3    25     0    66     1     0     0    28]]\n",
    "\n",
    "F1 Macro Score (Validation): 0.3483434719716329\n",
    "\n",
    "==================================================\n",
    "Training and Evaluating: Random Forest\n",
    "==================================================\n",
    "___________________________________________________________________________________________________________\n",
    "                                                     TRAIN                                                 \n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.75      0.54      0.63      7701\n",
    "           2       0.75      0.95      0.84    200073\n",
    "           3       0.66      0.19      0.30     46185\n",
    "           4       0.72      0.60      0.65     95874\n",
    "           5       0.70      0.67      0.68     29651\n",
    "           6       0.84      0.31      0.45      2721\n",
    "           7       0.89      0.56      0.69        57\n",
    "           8       0.73      0.61      0.67       275\n",
    "\n",
    "    accuracy                           0.74    382537\n",
    "   macro avg       0.75      0.55      0.61    382537\n",
    "weighted avg       0.73      0.74      0.71    382537\n",
    "\n",
    "Confusion Matrix (Train):\n",
    " [[  4148   2764    161    514    112      0      0      2]\n",
    " [  1180 190307   1529   5865   1176      3      1     12]\n",
    " [    71  27259   8967   7558   2290     28      0     12]\n",
    " [   119  31615   2109  57058   4861     80      2     30]\n",
    " [    28   1888    788   6925  19975     44      0      3]\n",
    " [     0     26     64   1514    281    833      1      2]\n",
    " [     0      2      1     20      2      0     32      0]\n",
    " [     0     30     23     52      1      0      0    169]]\n",
    "\n",
    "F1 Macro Score (Train): 0.6133063835157717\n",
    "___________________________________________________________________________________________________________\n",
    "                                                VALIDATION                                                 \n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.63      0.46      0.53      3263\n",
    "           2       0.73      0.92      0.81     85765\n",
    "           3       0.26      0.07      0.11     19810\n",
    "           4       0.58      0.49      0.53     41064\n",
    "           5       0.51      0.49      0.50     12669\n",
    "           6       0.07      0.02      0.03      1167\n",
    "           7       0.00      0.00      0.00        24\n",
    "           8       0.20      0.11      0.15       123\n",
    "\n",
    "    accuracy                           0.66    163885\n",
    "   macro avg       0.37      0.32      0.33    163885\n",
    "weighted avg       0.61      0.66      0.62    163885\n",
    "\n",
    "Confusion Matrix (Validation):\n",
    " [[ 1494  1278    85   323    81     0     0     2]\n",
    " [  629 79248  1227  3893   749     6     0    13]\n",
    " [   73 12349  1448  4601  1294    30     2    13]\n",
    " [  124 14801  2031 20264  3606   201    11    26]\n",
    " [   31  1053   634  4703  6211    37     0     0]\n",
    " [    1     8    45   952   140    21     0     0]\n",
    " [    0     0     0    20     2     1     0     1]\n",
    " [    2    36    12    58     0     1     0    14]]\n",
    "\n",
    "F1 Macro Score (Validation): 0.3339612886975133\n",
    "\n",
    "==================================================\n",
    "Training and Evaluating: Decision Tree\n",
    "==================================================\n",
    "___________________________________________________________________________________________________________\n",
    "                                                     TRAIN                                                 \n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.71      0.58      0.64      7701\n",
    "           2       0.74      0.96      0.84    200073\n",
    "           3       0.63      0.21      0.32     46185\n",
    "           4       0.73      0.58      0.65     95874\n",
    "           5       0.73      0.62      0.67     29651\n",
    "           6       0.95      0.27      0.42      2721\n",
    "           7       0.97      0.51      0.67        57\n",
    "           8       0.87      0.51      0.65       275\n",
    "\n",
    "    accuracy                           0.74    382537\n",
    "   macro avg       0.79      0.53      0.61    382537\n",
    "weighted avg       0.73      0.74      0.71    382537\n",
    "\n",
    "Confusion Matrix (Train):\n",
    " [[  4466   2617    119    415     84      0      0      0]\n",
    " [  1369 191881   1070   4831    919      0      0      3]\n",
    " [   153  28030   9767   6357   1870      5      0      3]\n",
    " [   228  32831   3105  55964   3706     26      1     13]\n",
    " [    61   2188   1179   7715  18501      6      0      1]\n",
    " [     2     39    114   1555    269    741      0      1]\n",
    " [     0      4      0     21      2      1     29      0]\n",
    " [     2     43     32     57      0      0      0    141]]\n",
    "\n",
    "F1 Macro Score (Train): 0.606305457131044\n",
    "___________________________________________________________________________________________________________\n",
    "                                                VALIDATION                                                 \n",
    "-----------------------------------------------------------------------------------------------------------\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.56      0.48      0.51      3263\n",
    "           2       0.72      0.93      0.81     85765\n",
    "           3       0.24      0.08      0.12     19810\n",
    "           4       0.59      0.46      0.52     41064\n",
    "           5       0.52      0.46      0.49     12669\n",
    "           6       0.10      0.03      0.05      1167\n",
    "           7       0.00      0.00      0.00        24\n",
    "           8       0.18      0.11      0.14       123\n",
    "\n",
    "    accuracy                           0.66    163885\n",
    "   macro avg       0.36      0.32      0.33    163885\n",
    "weighted avg       0.61      0.66      0.62    163885\n",
    "\n",
    "Confusion Matrix (Validation):\n",
    " [[ 1550  1244   103   289    74     1     0     2]\n",
    " [  779 79557  1297  3427   674     8     3    20]\n",
    " [  136 12641  1624  4158  1206    28     2    15]\n",
    " [  235 15490  2842 18923  3248   278    22    26]\n",
    " [   64  1250   892  4595  5821    45     1     1]\n",
    " [    6    15    76   895   135    40     0     0]\n",
    " [    0     2     2    16     2     2     0     0]\n",
    " [    5    40    15    43     2     3     1    14]]\n",
    "\n",
    "F1 Macro Score (Validation): 0.33016134284356835\n",
    "\n",
    "==================================================\n",
    "Training and Evaluating: SVM (RBF Kernel)\n",
    "==================================================\n",
    "Defaulting to user installation because normal site-packages is not writeable\n",
    "\n",
    "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
    "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
    "\n",
    "Collecting lightgbm\n",
    "  Downloading lightgbm-4.5.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
    "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\utilizador\\appdata\\roaming\\python\\python312\\site-packages (from lightgbm) (2.0.2)\n",
    "Requirement already satisfied: scipy in c:\\users\\utilizador\\appdata\\roaming\\python\\python312\\site-packages (from lightgbm) (1.14.1)\n",
    "Downloading lightgbm-4.5.0-py3-none-win_amd64.whl (1.4 MB)\n",
    "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
    "   --------------------- ------------------ 0.8/1.4 MB 4.2 MB/s eta 0:00:01\n",
    "   ---------------------------------------- 1.4/1.4 MB 4.0 MB/s eta 0:00:00\n",
    "Installing collected packages: lightgbm\n",
    "Successfully installed lightgbm-4.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d03be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLPClassifier...\n",
      "Model: MLPClassifier\n",
      "K-Fold F1 Score (Macro) Mean: 0.3361 (+/- 0.0074)\n",
      "Repeated K-Fold F1 Score (Macro) Mean: 0.3413 (+/- 0.0074)\n",
      "Stratified K-Fold F1 Score (Macro) Mean: 0.3379 (+/- 0.0117)\n",
      "\n",
      "Evaluating RandomForest...\n",
      "Model: RandomForestClassifier\n",
      "K-Fold F1 Score (Macro) Mean: 0.3382 (+/- 0.0081)\n",
      "Repeated K-Fold F1 Score (Macro) Mean: 0.3363 (+/- 0.0082)\n",
      "Stratified K-Fold F1 Score (Macro) Mean: 0.3358 (+/- 0.0117)\n",
      "\n",
      "Evaluating LogisticRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Utilizador\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "K-Fold F1 Score (Macro) Mean: 0.2996 (+/- 0.0034)\n",
      "Repeated K-Fold F1 Score (Macro) Mean: 0.3014 (+/- 0.0042)\n",
      "Stratified K-Fold F1 Score (Macro) Mean: 0.3020 (+/- 0.0059)\n",
      "\n",
      "Evaluating KNeighborsClassifier...\n",
      "Model: KNeighborsClassifier\n",
      "K-Fold F1 Score (Macro) Mean: 0.3191 (+/- 0.0031)\n",
      "Repeated K-Fold F1 Score (Macro) Mean: 0.3198 (+/- 0.0038)\n",
      "Stratified K-Fold F1 Score (Macro) Mean: 0.3185 (+/- 0.0087)\n",
      "\n",
      "Evaluating DecisionTree...\n",
      "Model: DecisionTreeClassifier\n",
      "K-Fold F1 Score (Macro) Mean: 0.3342 (+/- 0.0070)\n",
      "Repeated K-Fold F1 Score (Macro) Mean: 0.3263 (+/- 0.0086)\n",
      "Stratified K-Fold F1 Score (Macro) Mean: 0.3265 (+/- 0.0140)\n",
      "\n",
      "Evaluating GaussianNB...\n",
      "Model: GaussianNB\n",
      "K-Fold F1 Score (Macro) Mean: 0.1591 (+/- 0.0025)\n",
      "Repeated K-Fold F1 Score (Macro) Mean: 0.1592 (+/- 0.0029)\n",
      "Stratified K-Fold F1 Score (Macro) Mean: 0.1597 (+/- 0.0033)\n",
      "\n",
      "Evaluating RidgeClassifier...\n",
      "Model: RidgeClassifier\n",
      "K-Fold F1 Score (Macro) Mean: 0.2559 (+/- 0.0012)\n",
      "Repeated K-Fold F1 Score (Macro) Mean: 0.2560 (+/- 0.0013)\n",
      "Stratified K-Fold F1 Score (Macro) Mean: 0.2560 (+/- 0.0029)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold, cross_val_score\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.linear_model import RidgeClassifier\n",
    "# from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# # Define K-Fold cross-validation\n",
    "# kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# # Define Repeated K-Fold cross-validation\n",
    "# repeated_kfold = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "# # Define Stratified K-Fold cross-validation\n",
    "# skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# # Define the F1 macro scorer\n",
    "# f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# # Decide the best model\n",
    "# def evaluate_model(model, X, y, kfold, repeated_kfold, skfold):\n",
    "#     kfold_results = cross_val_score(model, X, y, cv=kfold, scoring=f1_macro_scorer)\n",
    "#     repeated_kfold_results = cross_val_score(model, X, y, cv=repeated_kfold, scoring=f1_macro_scorer)\n",
    "#     skfold_results = cross_val_score(model, X, y, cv=skfold, scoring=f1_macro_scorer)\n",
    "\n",
    "#     print(f\"Model: {model.__class__.__name__}\")\n",
    "#     print(f\"K-Fold F1 Score (Macro) Mean: {kfold_results.mean():.4f} (+/- {kfold_results.std():.4f})\")\n",
    "#     print(f\"Repeated K-Fold F1 Score (Macro) Mean: {repeated_kfold_results.mean():.4f} (+/- {repeated_kfold_results.std():.4f})\")\n",
    "#     print(f\"Stratified K-Fold F1 Score (Macro) Mean: {skfold_results.mean():.4f} (+/- {skfold_results.std():.4f})\")\n",
    "#     print(\"\")\n",
    "\n",
    "# # Define models\n",
    "# models = {\n",
    "#     \"MLPClassifier\": MLPClassifier(max_iter=500),\n",
    "#     \"RandomForest\": RandomForestClassifier(),\n",
    "#     \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "#     \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "#     \"DecisionTree\": DecisionTreeClassifier(),\n",
    "#     \"GaussianNB\": GaussianNB(),\n",
    "#     \"RidgeClassifier\": RidgeClassifier()\n",
    "# }\n",
    "\n",
    "# # Evaluate each model using K-Fold and Repeated K-Fold cross-validation\n",
    "# for model_name, model in models.items():\n",
    "#     print(f\"Evaluating {model_name}...\")\n",
    "#     evaluate_model(model, X_train, y_train, kfold, repeated_kfold, skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06887d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "746557b1",
   "metadata": {},
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SVM (balanced)': SVC(class_weight='balanced'),\n",
    "    \"SVM\": SVC(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Random Forest (balanced)': RandomForestClassifier(class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Neural Network': MLPClassifier(solver='adam',max_iter=1000),\n",
    "}\n",
    "\n",
    "# F1_Scores\n",
    "f1_scores = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Fitting {model_name}...\")\n",
    "    \n",
    "    # Use the model directly on the validation set\n",
    "    y_pred_val = model.fit(X_mult_train, y_mult_train).predict(X_mult_val)\n",
    "    f1_val = f1_score(y_mult_val, y_pred_val, pos_label=1,average=\"weighted\")\n",
    "    \n",
    "    f1_scores.append([f1_val])\n",
    "\n",
    "# Create DataFrame with results\n",
    "f1_res = pd.DataFrame({\n",
    "    \"F1_Scores\": [result[0] for result in f1_scores],\n",
    "    \"Algorithm\": list(models.keys())\n",
    "})\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def metrics(y_train, pred_train , y_val, pred_val):\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                     TRAIN                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    print(confusion_matrix(y_train, pred_train))\n",
    "\n",
    "\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                VALIDATION                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_val, pred_val))\n",
    "    print(confusion_matrix(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b5a4dd",
   "metadata": {},
   "source": [
    "Modelos Tradicionais de Machine Learning\n",
    "\n",
    "Logistic Regression Multiclasse\n",
    "Funcionamento: Extensão da regressão logística binária para prever várias categorias com técnicas como One-vs-Rest (OvR) ou Softmax.\n",
    "Vantagens: Simples de entender, eficiente em datasets pequenos.\n",
    "Limitações: Não lida bem com relações complexas entre as variáveis ou entre os rótulos.\n",
    "Escalabilidade: Precisa de dados normalizados.\n",
    "\n",
    "Decision Trees (DT)\n",
    "Funcionamento: Constrói árvores de decisão com base em critérios de impureza (como Gini ou Entropia).\n",
    "Vantagens: Funciona com Ordinal Encoding, não exige normalização.\n",
    "Limitações: Tende a sobreajustar em datasets pequenos.\n",
    "\n",
    "Random Forest (RF)\n",
    "Funcionamento: Ensemble de árvores de decisão para reduzir o sobreajuste.\n",
    "Vantagens: Robusto contra overfitting, lida bem com categorical encoding.\n",
    "Limitações: Pode ser mais lento em grandes datasets.\n",
    "\n",
    "Gradient Boosting (e.g., XGBoost, LightGBM)\n",
    "Funcionamento: Constrói modelos iterativamente, corrigindo erros das previsões anteriores.\n",
    "Vantagens: Excelente para dados tabulares com muitas categorias.\n",
    "Limitações: Exige Ordinal Encoding ou One-Hot Encoding.\n",
    "\n",
    "\n",
    "\n",
    "Modelos Baseados em Redes Neurais\n",
    "\n",
    "Multilayer Perceptron (MLP)\n",
    "Funcionamento: Redes totalmente conectadas com ativação Softmax para saída multicategoria.\n",
    "Vantagens: Flexível, pode capturar relações complexas.\n",
    "Limitações: Exige grande volume de dados, sensível à escala.\n",
    "\n",
    "Convolutional Neural Networks (CNNs)\n",
    "Funcionamento: Modelos baseados em convolução, ideais para imagens ou séries temporais.\n",
    "Vantagens: Excelente para dados espaciais.\n",
    "Limitações: Ineficiente para dados tabulares ou não estruturados.\n",
    "\n",
    "Recurrent Neural Networks (RNNs) e Transformers\n",
    "Funcionamento: Ideais para dados sequenciais (texto ou séries temporais).\n",
    "Vantagens: Capturam dependências temporais.\n",
    "Limitações: Mais complexos de treinar.\n",
    "Modelos de Similaridade e Vizinho Mais Próximo\n",
    "K-Nearest Neighbors (KNN)\n",
    "Funcionamento: Classifica com base nos rótulos dos vizinhos mais próximos.\n",
    "Vantagens: Simples de implementar, não precisa de treinamento explícito.\n",
    "Limitações: Sensível à escala (precisa de normalização).\n",
    "\n",
    "\n",
    "\n",
    "Modelos Estatísticos\n",
    "\n",
    "Naive Bayes\n",
    "Funcionamento: Calcula probabilidades assumindo independência entre atributos.\n",
    "Vantagens: Rápido, eficiente com dados textuais (TF-IDF).\n",
    "Limitações: Assume independência entre variáveis (o que nem sempre é verdade).\n",
    "Considerações sobre Pré-processamento\n",
    "Encoding de Variáveis Categóricas:\n",
    "Ordinal Encoding: Adequado para modelos baseados em árvores, mas não para métodos baseados em distância como KNN.\n",
    "One-Hot Encoding: Necessário para redes neurais e modelos lineares (Logistic Regression, SVM).\n",
    "Normalização:\n",
    "Essencial para algoritmos baseados em distância (KNN, SVM) e redes neurais.\n",
    "Dados Desequilibrados:\n",
    "Métodos como Oversampling (SMOTE) ou ajuste de pesos nas classes podem ser usados.\n",
    "\n",
    "\n",
    "\n",
    "!!!!!!!!!!!!!!!!!6 - If you use GridSearch or something similar like RandomSearch please create your final model in another cell that considers the best parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
